---
marp: true
title: 24 Jun 2024
size: 16:9
math: mathjax
theme: am_dark
paginate: true
headingDivider: [2,3]
footer: Kashu Yamazaki, 2024
# backgroundImage: url('https://marp.app/assets/hero-background.svg')
---

<!-- _class: cover_b -->
<!-- _header: "" -->
<!-- _footer: "" -->
<!-- _paginate: "" -->
<!-- _backgroundImage: url('https://marp.app/assets/hero-background.svg') -->

# Robot Perception and Control

###### Foundation Models for Robotics

Last updated: Jul / 25 /2024
Kashu Yamazaki
kyamazak@andrew.cmu.edu

---

<!-- _class: toc_a -->
<!-- _header: "" -->
<!-- _footer: "" -->
<!-- _paginate: "" -->

- [Datasets](#3)
- [Models]()

## From Transformers to Foundation Models

![](https://api.wandb.ai/files/vincenttu/images/projects/37228380/5a69d608.png)

##  1. Datasets

<!-- _class: trans -->
<!-- _footer: "" -->
<!-- _paginate: "" -->


## 1.1 Open X-Embodiment

![#center](https://robotics-transformer-x.github.io/img/overview.png)

A large-scale collection of datasets from 22 different robots collected through a collaboration between 21 institutions, demonstrating 527 skills (160266 tasks). The dataset follows the `RLDS` format.

## 1.2 DROID

DROID uses the same hardware setup using Panda robot across all 13 institutions to streamline data collection while maximizing portability and flexibility.

![bg right:35% w:90%](https://droid-dataset.github.io/figures/droid_setup.png)
![bg vertical right:35% w:90%](https://droid-dataset.github.io/figures/droid_viewpoint_distribution.png)

##  2. Models

<!-- _class: trans -->
<!-- _footer: "" -->
<!-- _paginate: "" -->

## RT1



## RT2



![bg right:40% 100%](img/rt2_arch.png)

## RT-X

## Octo [arxiv](https://arxiv.org/abs/2405.12213)

![#center w:800](https://octo-models.github.io/architecture.jpg)